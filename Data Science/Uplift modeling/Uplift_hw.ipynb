{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kus3pTYqMpWQ"
      },
      "outputs": [],
      "source": [
        "!wget -q http://go.criteo.net/criteo-research-uplift-v2.1.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltFaIpPTM_rD",
        "outputId": "7b0b5f9a-7f94-4048-ede0-6f510d0d4c4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gzip: /content/criteo-research-uplift-v2.1.csv already exists; do you wish to overwrite (y or n)? "
          ]
        }
      ],
      "source": [
        "!gzip -d /content/criteo-research-uplift-v2.1.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGjsnNTmN7Lg"
      },
      "outputs": [],
      "source": [
        "! pip install -q scikit-uplift causalml catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9_pdlhoN-dq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Импортируем S- и T- learner`ы  (SoloModel и TwoModels) из библиотеки scikit-uplift (sklift)\n",
        "from sklift.models import SoloModel, TwoModels\n",
        "\n",
        "# Импортируем S- и T-learner`ы (BaseSClassifier и BaseTClassifier) из библиотеки CausalML\n",
        "# Нам нужны именно Classifier, так как мы будем решать задачу классификации\n",
        "# Аналогичные реализации (Regressor) есть и для задач регрессии\n",
        "from causalml.inference.meta import BaseSClassifier, BaseTClassifier\n",
        "\n",
        "\n",
        "# В качестве классификатора воспользуемся моделью градиентного бустинга от Яндекса (CatBoost)\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Прочитаем файл с данными\n",
        "df = pd.read_csv(\"/content/criteo-research-uplift-v2.1.csv\")\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-IVMfQjO-Mn"
      },
      "outputs": [],
      "source": [
        "df['treatment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yf8aa764QpHN"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2qTnF66YTEe"
      },
      "outputs": [],
      "source": [
        "list(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14l4Vln2Qu-N"
      },
      "outputs": [],
      "source": [
        "#todo(alex) here\n",
        "# Определим колонки с факторами, тритментом и таргетом\n",
        "feature_cols = ['f0',\n",
        "                'f1',\n",
        "                'f2',\n",
        "                'f3',\n",
        "                'f4',\n",
        "                'f5',\n",
        "                'f6',\n",
        "                'f7',\n",
        "                'f8',\n",
        "                'f9',\n",
        "                'f10',\n",
        "                'f11']\n",
        "\n",
        "target_col = 'conversion'\n",
        "treatment_col = 'treatment'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYl3tll-Yw_N"
      },
      "outputs": [],
      "source": [
        "df_discount_train, df_discount_test = train_test_split(\n",
        "    df,\n",
        "    stratify=df[[treatment_col, target_col]],\n",
        "    random_state=13,\n",
        "    test_size=0.3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mc98NsdFY6uv"
      },
      "outputs": [],
      "source": [
        "# Возьмем функцию для оценки qini-curve с прошлого занятия\n",
        "def qini_df(df, title='train', figsize=(5, 3)):\n",
        "    # Отранжируем выборку по значению uplift в убывающем порядке\n",
        "    ranked = df.sort_values(\"uplift_score\", ascending=False)\n",
        "\n",
        "    N_c = sum(ranked['target_class'] <= 1)\n",
        "    N_t = sum(ranked['target_class'] >= 2)\n",
        "\n",
        "    # Посчитаем в отсортированном датафрейме основные показатели, которые используются при расчете qini\n",
        "    ranked['n_c1'] = 0\n",
        "    ranked['n_t1'] = 0\n",
        "    ranked.loc[ranked.target_class == 1,'n_c1'] = 1\n",
        "    ranked.loc[ranked.target_class == 3,'n_t1'] = 1\n",
        "    ranked['n_c1/nc'] = ranked.n_c1.cumsum() / N_c\n",
        "    ranked['n_t1/nt'] = ranked.n_t1.cumsum() / N_t\n",
        "\n",
        "    # Посчитаем qini curve и рандомную прямую под ней\n",
        "    ranked['uplift'] = round(ranked['n_t1/nt'] - ranked['n_c1/nc'],5)\n",
        "    # Добавим случайную кривую\n",
        "    ranked['random_uplift'] = round(ranked[\"uplift_score\"].rank(pct=True, ascending=False) * ranked['uplift'].iloc[-1],5)\n",
        "\n",
        "    ranked[\"n\"] = ranked[\"uplift_score\"].rank(pct=True, ascending=False)\n",
        "\n",
        "    # Немного кода для визуализации\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    plt.plot(ranked['n'], ranked['uplift'], color='r', label='Model')\n",
        "    plt.plot(ranked['n'], ranked['random_uplift'], color='b', label='RandomModel')\n",
        "    plt.legend()\n",
        "    plt.title('Qini-curve for {} samples'.format(title))\n",
        "    plt.show()\n",
        "    quni_score = (ranked['uplift'] - ranked['random_uplift']).sum()\n",
        "    print('Qini score: {:.3f}'.format(quni_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skPx-OOHZXah"
      },
      "outputs": [],
      "source": [
        "# Давайте по данным построим S-learner\n",
        "\n",
        "# Создадим базовый S-learner\n",
        "s_learner = BaseSClassifier(learner=CatBoostClassifier(random_seed=13, verbose=0))\n",
        "\n",
        "# Для обучения нам нужны датафрем с факторами, колонка с фактом воздействия\n",
        "s_learner.fit(X=df_discount_train[feature_cols],\n",
        "              treatment=df_discount_train[treatment_col],\n",
        "              y=df_discount_train[target_col])\n",
        "\n",
        "# Сделаем предсказание uplift-эффекта на обучающей выборке\n",
        "uplift_vals = s_learner.predict(np.array(df_discount_train[feature_cols].values.copy()))\n",
        "df_discount_train['uplift_score'] = uplift_vals\n",
        "\n",
        "# Сделаем предсказание uplift-эффекта на тестовой выборке\n",
        "uplift_vals = s_learner.predict(np.array(df_discount_test[feature_cols].values.copy()))\n",
        "df_discount_test['uplift_score'] = uplift_vals\n",
        "\n",
        "# Мы получили какие-то значения рамках решения задачи классификации, давайте посмотрим на qini score\n",
        "qini_df(df_discount_train, title='train')\n",
        "qini_df(df_discount_test, title='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJURl0juaCp8"
      },
      "outputs": [],
      "source": [
        "# Давайте по данным построим T-learner\n",
        "\n",
        "# Создадим базовый T-learner\n",
        "t_learner = BaseTClassifier(learner=CatBoostClassifier(random_seed=13, verbose=0))\n",
        "\n",
        "# Для обучения нам нужны датафрем с факторами, колонка с фактом воздействия\n",
        "t_learner.fit(X=df_discount_train[feature_cols],\n",
        "              treatment=df_discount_train[treatment_col],\n",
        "              y=df_discount_train[target_col])\n",
        "\n",
        "# Сделаем предсказание uplift-эффекта на обучающей выборке\n",
        "uplift_vals = t_learner.predict(np.array(df_discount_train[feature_cols].values.copy()))\n",
        "df_discount_train['uplift_score'] = uplift_vals\n",
        "\n",
        "# Сделаем предсказание uplift-эффекта на тестовой выборке\n",
        "uplift_vals = t_learner.predict(np.array(df_discount_test[feature_cols].values.copy()))\n",
        "df_discount_test['uplift_score'] = uplift_vals\n",
        "\n",
        "# Мы получили какие-то значения рамках решения задачи классификации, давайте посмотрим на qini score\n",
        "qini_df(df_discount_train, title='train')\n",
        "qini_df(df_discount_test, title='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTRomLPaaimC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "\n",
        "# Импортируем X- и R-learner`ы (BaseXClassifier и BaseRClassifier) из библиотеки CausalML\n",
        "# Нам нужны именно Classifier, так как мы будем решать задачу классификации\n",
        "# Аналогичные реализации (Regressor) есть и для задач регрессии\n",
        "from causalml.inference.meta import BaseXClassifier, BaseRClassifier\n",
        "from catboost import CatBoostClassifier, CatBoostRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZdRcjpKaiUR"
      },
      "outputs": [],
      "source": [
        "# Давайте по данным построим X-learner\n",
        "\n",
        "# Создадим базовый X-learner\n",
        "x_learner = BaseXClassifier(\n",
        "    outcome_learner=CatBoostClassifier(depth=5, random_seed=13, verbose=0),\n",
        "    effect_learner=LinearRegression()\n",
        ")\n",
        "\n",
        "# Для обучения нам нужны датафрем с факторами, колонка с фактом воздействия\n",
        "x_learner.fit(\n",
        "    X=df_discount_train[feature_cols],\n",
        "    treatment=df_discount_train[treatment_col],\n",
        "    y=df_discount_train[target_col]\n",
        ")\n",
        "\n",
        "# Сделаем предсказание uplift-эффекта на обучающей выборке\n",
        "uplift_vals = x_learner.predict(np.array(df_discount_train[feature_cols].values.copy()))\n",
        "df_discount_train['uplift_score'] = uplift_vals\n",
        "\n",
        "# Сделаем предсказание uplift-эффекта на тестовой выборке\n",
        "uplift_vals = x_learner.predict(np.array(df_discount_test[feature_cols].values.copy()))\n",
        "df_discount_test['uplift_score'] = uplift_vals\n",
        "\n",
        "# Мы получили какие-то значения рамках решения задачи классификации, давайте посмотрим на qini score\n",
        "qini_df(df_discount_train, title='train')\n",
        "qini_df(df_discount_test, title='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vovKyg8WauRE"
      },
      "outputs": [],
      "source": [
        "# Давайте по данным построим R-learner\n",
        "\n",
        "# Создадим базовый R-learner\n",
        "r_learner = BaseRClassifier(\n",
        "    outcome_learner=CatBoostClassifier(depth=5, random_seed=13, verbose=0),\n",
        "    effect_learner=LinearRegression(),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Для обучения нам нужны датафрем с факторами, колонка с фактом воздействия\n",
        "r_learner.fit(X=df_discount_train[feature_cols],\n",
        "              treatment=df_discount_train[treatment_col],\n",
        "              y=df_discount_train[target_col])\n",
        "\n",
        "# Сделаем предсказание uplift-эффекта на обучающей выборке\n",
        "uplift_vals = r_learner.predict(np.array(df_discount_train[feature_cols].values.copy()))\n",
        "df_discount_train['uplift_score'] = uplift_vals\n",
        "\n",
        "# Сделаем предсказание uplift-эффекта на тестовой выборке\n",
        "uplift_vals = r_learner.predict(np.array(df_discount_test[feature_cols].values.copy()))\n",
        "df_discount_test['uplift_score'] = uplift_vals\n",
        "\n",
        "# Мы получили какие-то значения рамках решения задачи классификации, давайте посмотрим на qini score\n",
        "qini_df(df_discount_train, title='train')\n",
        "qini_df(df_discount_test, title='test')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Продолжаем решать нашу постановку как задачу классификации - для этого возьмем одно Uplift-дерево и случайный лес\n",
        "# помним, что основное отличие - это функция разбиения в листе\n",
        "from causalml.inference.tree import UpliftTreeClassifier, UpliftRandomForestClassifier\n",
        "from causalml.inference.tree import uplift_tree_string, uplift_tree_plot"
      ],
      "metadata": {
        "id": "_RG8sjpLGIuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем простое дерево.\n",
        "uplift_tree = UpliftTreeClassifier(\n",
        "    max_depth=5, min_samples_leaf=200,\n",
        "    min_samples_treatment=50,\n",
        "    n_reg=100, evaluationFunction='ED',\n",
        "    control_name='0', random_state=42\n",
        ")\n",
        "\n",
        "# Для обучения нам нужны датафрем с факторами, колонка с фактом воздействия\n",
        "# Обратите внимание, что для использования деревьев из CausalML нам необходимо преобразовать фактор воздействия в строку\n",
        "uplift_tree.fit(\n",
        "    df_discount_train[feature_cols].values,\n",
        "    treatment=df_discount_train[treatment_col].apply(str).values,\n",
        "    y=df_discount_train[target_col].values\n",
        ")\n",
        "\n",
        "# Сделаем предсказание uplift-эффекта на обучающей выборке\n",
        "# Функция predict у деревьев возвращает uplift-эффекты для каждой группы воздействия\n",
        "# Нас интересует только наличие воздействия (столбец под индексом 1)\n",
        "uplift_vals = uplift_tree.predict(np.array(df_discount_train[feature_cols].values.copy()))[:, 1]\n",
        "df_discount_train['uplift_score'] = uplift_vals\n",
        "\n",
        "# Сделаем предсказание uplift-эффекта на тестовой выборке\n",
        "# Функция predict у деревьев возвращает uplift-эффекты для каждой группы воздействия\n",
        "# Нас интересует только наличие воздействия (столбец под индексом 1)\n",
        "uplift_vals = uplift_tree.predict(np.array(df_discount_test[feature_cols].values.copy()))[:, 1]\n",
        "df_discount_test['uplift_score'] = uplift_vals\n",
        "\n",
        "# Мы получили какие-то значения рамках решения задачи классификации, давайте посмотрим на qini score\n",
        "qini_df(df_discount_train, title='train')\n",
        "qini_df(df_discount_test, title='test')"
      ],
      "metadata": {
        "id": "gvrfWUGlGRoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Давайте визуализируем наше простейшее дерево\n",
        "from IPython.display import Image\n",
        "# Вызываем функцию для визуализации:\n",
        "graph = uplift_tree_plot(uplift_tree.fitted_uplift_tree, feature_cols)\n",
        "Image(graph.create_png())"
      ],
      "metadata": {
        "id": "Yzk61G4VGT5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем простое дерево.\n",
        "uplift_forest = UpliftRandomForestClassifier(\n",
        "    n_estimators=100, max_depth=5, min_samples_leaf=100,\n",
        "    min_samples_treatment=50,\n",
        "    n_reg=100, evaluationFunction='ED',\n",
        "    control_name='0', random_state=42\n",
        ")\n",
        "\n",
        "# Для обучения нам нужны датафрем с факторами, колонка с фактом воздействия\n",
        "# Обратите внимание, что для использования деревьев из CausalML нам необходимо преобразовать фактор воздействия в строку\n",
        "uplift_forest.fit(\n",
        "    df_discount_train[feature_cols].values,\n",
        "    treatment=df_discount_train[treatment_col].apply(str).values,\n",
        "    y=df_discount_train[target_col].values\n",
        ")\n",
        "\n",
        "# Сделаем предсказание uplift-эффекта на обучающей выборке\n",
        "# Функция predict у деревьев возвращает uplift-эффекты для каждой группы воздействия\n",
        "# Нас интересует только наличие воздействия (столбец под индексом 1)\n",
        "uplift_vals = uplift_forest.predict(np.array(df_discount_train[feature_cols].values.copy()))\n",
        "df_discount_train['uplift_score'] = uplift_vals\n",
        "\n",
        "# Сделаем предсказание uplift-эффекта на тестовой выборке\n",
        "# Функция predict у деревьев возвращает uplift-эффекты для каждой группы воздействия\n",
        "# Нас интересует только наличие воздействия (столбец под индексом 1)\n",
        "uplift_vals = uplift_forest.predict(np.array(df_discount_test[feature_cols].values.copy()))\n",
        "df_discount_test['uplift_score'] = uplift_vals\n",
        "\n",
        "# Мы получили какие-то значения рамках решения задачи классификации, давайте посмотрим на qini score\n",
        "qini_df(df_discount_train, title='train')\n",
        "qini_df(df_discount_test, title='test')"
      ],
      "metadata": {
        "id": "dP12JNEmGWe_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}